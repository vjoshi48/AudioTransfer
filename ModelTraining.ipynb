{"cells":[{"cell_type":"markdown","metadata":{"id":"yxHfijC2lkwi"},"source":["# Training script\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting albumentations\n","  Downloading albumentations-1.3.0-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from albumentations) (6.0)\n","Requirement already satisfied: numpy>=1.11.1 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from albumentations) (1.23.5)\n","Requirement already satisfied: scipy in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from albumentations) (1.10.1)\n","Collecting qudida>=0.0.4\n","  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n","Collecting scikit-image>=0.16.1\n","  Downloading scikit_image-0.20.0-cp39-cp39-macosx_12_0_arm64.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting opencv-python-headless>=4.1.1\n","  Downloading opencv_python_headless-4.7.0.72-cp37-abi3-macosx_11_0_arm64.whl (32.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.6/32.6 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (4.4.0)\n","Requirement already satisfied: scikit-learn>=0.19.1 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n","Collecting imageio>=2.4.1\n","  Downloading imageio-2.27.0-py3-none-any.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting scipy\n","  Downloading scipy-1.9.1-cp39-cp39-macosx_12_0_arm64.whl (29.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.9/29.9 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting PyWavelets>=1.1.1\n","  Downloading PyWavelets-1.4.1-cp39-cp39-macosx_11_0_arm64.whl (4.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx>=2.8 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (3.0)\n","Collecting lazy_loader>=0.1\n","  Downloading lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n","Collecting tifffile>=2019.7.26\n","  Downloading tifffile-2023.4.12-py3-none-any.whl (219 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.4/219.4 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow>=9.0.1 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (9.4.0)\n","Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (22.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n","Installing collected packages: tifffile, scipy, PyWavelets, opencv-python-headless, lazy_loader, imageio, scikit-image, qudida, albumentations\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.10.1\n","    Uninstalling scipy-1.10.1:\n","      Successfully uninstalled scipy-1.10.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","librosa 0.9.2 requires numba>=0.45.1, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed PyWavelets-1.4.1 albumentations-1.3.0 imageio-2.27.0 lazy_loader-0.2 opencv-python-headless-4.7.0.72 qudida-0.0.4 scikit-image-0.20.0 scipy-1.9.1 tifffile-2023.4.12\n","Requirement already satisfied: librosa in /Users/varunjoshi/.local/lib/python3.9/site-packages (0.9.2)\n","Requirement already satisfied: resampy>=0.2.2 in /Users/varunjoshi/.local/lib/python3.9/site-packages (from librosa) (0.4.2)\n","Requirement already satisfied: packaging>=20.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from librosa) (22.0)\n","Collecting numba>=0.45.1\n","  Downloading numba-0.56.4-cp39-cp39-macosx_11_0_arm64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from librosa) (1.23.5)\n","Requirement already satisfied: scikit-learn>=0.19.1 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from librosa) (1.2.2)\n","Requirement already satisfied: pooch>=1.0 in /Users/varunjoshi/.local/lib/python3.9/site-packages (from librosa) (1.6.0)\n","Requirement already satisfied: decorator>=4.0.10 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from librosa) (5.1.1)\n","Requirement already satisfied: soundfile>=0.10.2 in /Users/varunjoshi/.local/lib/python3.9/site-packages (from librosa) (0.11.0)\n","Requirement already satisfied: scipy>=1.2.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from librosa) (1.9.1)\n","Requirement already satisfied: audioread>=2.1.9 in /Users/varunjoshi/.local/lib/python3.9/site-packages (from librosa) (3.0.0)\n","Requirement already satisfied: joblib>=0.14 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from librosa) (1.2.0)\n","Requirement already satisfied: setuptools in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from numba>=0.45.1->librosa) (65.6.3)\n","Collecting llvmlite<0.40,>=0.39.0dev0\n","  Downloading llvmlite-0.39.1-cp39-cp39-macosx_11_0_arm64.whl (23.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting appdirs>=1.3.0\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from pooch>=1.0->librosa) (2.28.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n","Requirement already satisfied: pycparser in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.14)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n","Installing collected packages: appdirs, llvmlite, numba\n","Successfully installed appdirs-1.4.4 llvmlite-0.39.1 numba-0.56.4\n","Requirement already satisfied: torch in /opt/homebrew/anaconda3/lib/python3.9/site-packages (2.0.0)\n","Requirement already satisfied: filelock in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from torch) (3.9.0)\n","Requirement already satisfied: typing-extensions in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from torch) (4.4.0)\n","Requirement already satisfied: networkx in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from torch) (3.0)\n","Requirement already satisfied: sympy in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from torch) (1.11.1)\n","Requirement already satisfied: jinja2 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from torch) (2.11.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)\n","Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/anaconda3/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: numpy in /opt/homebrew/anaconda3/lib/python3.9/site-packages (1.23.5)\n"]}],"source":["!pip install albumentations\n","!pip install librosa\n","!pip install torch\n","!pip install numpy"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ma9tVIZKli3u"},"outputs":[],"source":["import librosa\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import cv2\n","from pdb import set_trace\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import os\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.utils.checkpoint as checkpoint\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","from torchvision.utils import save_image\n","\n","import soundfile\n","import sys\n","from tqdm import tqdm\n","import random"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"AzpStDT-OenA"},"outputs":[],"source":["os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:32\"\n","max_size_x = 1025\n","max_size_y = 650\n","DEVICE = 'cuda'\n","TRAIN_DIR = 'Images/train'\n","VAL_DIR = 'Images/val'\n","BATCH_SIZE = 1\n","LEARNING_RATE = 1e-5\n","LAMBDA_IDENTITY = 0.0\n","LAMBDA_CYCLE = 10\n","NUM_WORKERS = 0\n","NUM_EPOCHS = 1\n","LOAD_MODEL = False\n","SAVE_MODEL = True\n","CHECKPOINT_GEN_Trap = 'checkpoints/genh.pth.tar'\n","CHECKPOINT_GEN_Rock = 'checkpoints/genz.pth.tar'\n","CHECKPOINT_CRITIC_Trap = 'checkpoints/critich.pth.tar'\n","CHECKPOINT_CRITIC_Rock = 'checkpoints/criticz.pth.tar'\n","\n","## LOSS ARRAYS \n","\n","D_Trap_real_loss_array = []\n","D_Trap_fake_loss_array = []\n","D_Trap_loss_array =  []\n","\n","D_Rock_real_loss_array = []\n","D_Rock_fake_loss_array = []\n","D_Rock_loss_array = []\n","\n","D_loss_array = []\n","\n","loss_G_Trap_array = []\n","loss_G_Rock_array = []\n","\n","cycle_rock_loss_array = []\n","cycle_trap_loss_array = []\n","\n","G_loss_array = []\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"_vCoaw31Oh01"},"outputs":[],"source":["def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n","    print(\"=> Saving checkpoint\")\n","    checkpoint = {\n","        \"state_dict\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","    }\n","    torch.save(checkpoint, filename)\n","\n","\n","def load_checkpoint(checkpoint_file, model, optimizer, lr):\n","    print(\"=> Loading checkpoint\")\n","    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n","\n","    # If we don't do this then it will just have learning rate of old checkpoint\n","    # and it will lead to many hours of debugging \\:\n","    for param_group in optimizer.param_groups:\n","        param_group[\"lr\"] = lr\n","\n","def seed_everything(seed=42):\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Vbe96oiWO6Wd"},"outputs":[],"source":["class TrapRockDataset(Dataset):\n","    def __init__(self, root_rock, root_trap, transform=None):\n","        self.root_rock = root_rock\n","        self.root_trap = root_trap\n","        self.transform = transform\n","\n","        self.rock_images = os.listdir(root_rock)\n","        self.trap_images = os.listdir(root_trap)\n","        self.length_dataset = max(len(self.rock_images), len(self.trap_images)) # 1000, 1500\n","        self.rock_len = len(self.rock_images)\n","        self.trap_len = len(self.trap_images)\n","\n","    def __len__(self):\n","        return self.length_dataset\n","\n","    def __getitem__(self, index):\n","        rock_img = self.rock_images[index % self.rock_len]\n","        trap_img = self.trap_images[index % self.trap_len]\n","\n","        rock_path = os.path.join(self.root_rock, rock_img)\n","        trap_path = os.path.join(self.root_trap, trap_img)\n","\n","        rock_img = np.array(Image.open(rock_path))\n","        trap_img = np.array(Image.open(trap_path))\n","\n","        if self.transform:\n","            #set_trace()\n","            augmentations = self.transform(image=rock_img, image0=trap_img)\n","            rock_img = augmentations[\"image\"]\n","            trap_img = augmentations[\"image0\"]\n","        # set_trace()\n","        return rock_img, trap_img"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"5_5k9YRXaC9U"},"outputs":[],"source":["class Block(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels,\n","                out_channels,\n","                4,\n","                stride,\n","                1,\n","                bias=True,\n","                padding_mode=\"reflect\",\n","            ),\n","            nn.InstanceNorm2d(out_channels),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"q0zk81fse006"},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, in_channels=1, features=[64, 128, 256, 512]):\n","        super().__init__()\n","        self.initial = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels,\n","                features[0],\n","                kernel_size=4,\n","                stride=2,\n","                padding=1,\n","                padding_mode=\"reflect\",\n","            ),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","\n","        layers = []\n","        in_channels = features[0]\n","        for feature in features[1:]:\n","            layers.append(\n","                Block(in_channels, feature, stride=1 if feature == features[-1] else 2)\n","            )\n","            in_channels = feature\n","        layers.append(\n","            nn.Conv2d(\n","                in_channels,\n","                1,\n","                kernel_size=4,\n","                stride=1,\n","                padding=1,\n","                padding_mode=\"reflect\",\n","            )\n","        )\n","        self.model = nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        #set_trace()\n","        #x = x.unsqueeze(1)\n","        x = self.initial(x)\n","        return torch.sigmoid(self.model(x))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"XZTu5RLze5t1"},"outputs":[],"source":["class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, down=True, use_act=True, **kwargs):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs)\n","            if down\n","            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n","            nn.InstanceNorm2d(out_channels),\n","            nn.ReLU(inplace=True) if use_act else nn.Identity(),\n","        )\n","\n","    def forward(self, x):\n","        return self.conv(x)\n","\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, channels):\n","        super().__init__()\n","        self.block = nn.Sequential(\n","            ConvBlock(channels, channels, kernel_size=3, padding=1),\n","            ConvBlock(channels, channels, use_act=False, kernel_size=3, padding=1),\n","        )\n","\n","    def forward(self, x):\n","        return x + self.block(x)\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"vu07MZhCfT3D"},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, img_channels, num_features=64, num_residuals=9):\n","        super().__init__()\n","        self.initial = nn.Sequential(\n","            nn.Conv2d(\n","                img_channels,\n","                num_features,\n","                kernel_size=7,\n","                stride=1,\n","                padding=3,\n","                padding_mode=\"reflect\",\n","            ),\n","            nn.InstanceNorm2d(num_features),\n","            nn.ReLU(inplace=True),\n","        )\n","        self.down_blocks = nn.ModuleList(\n","            [\n","                ConvBlock(\n","                    num_features, num_features * 2, kernel_size=3, stride=2, padding=1\n","                ),\n","                ConvBlock(\n","                    num_features * 2,\n","                    num_features * 4,\n","                    kernel_size=3,\n","                    stride=2,\n","                    padding=1,\n","                ),\n","            ]\n","        )\n","        self.res_blocks = nn.Sequential(\n","            *[ResidualBlock(num_features * 4) for _ in range(num_residuals)]\n","        )\n","        self.up_blocks = nn.ModuleList(\n","            [\n","                ConvBlock(\n","                    num_features * 4,\n","                    num_features * 2,\n","                    down=False,\n","                    kernel_size=3,\n","                    stride=2,\n","                    padding=1,\n","                    output_padding=1,\n","                ),\n","                ConvBlock(\n","                    num_features * 2,\n","                    num_features * 1,\n","                    down=False,\n","                    kernel_size=3,\n","                    stride=2,\n","                    padding=1,\n","                    output_padding=1,\n","                ),\n","            ]\n","        )\n","\n","        self.last = nn.Conv2d(\n","            num_features * 1,\n","            img_channels,\n","            kernel_size=7,\n","            stride=1,\n","            padding=3,\n","            padding_mode=\"reflect\",\n","        )\n","\n","    def forward(self, x):\n","        x = self.initial(x)\n","        for layer in self.down_blocks:\n","            x = layer(x)\n","        x = checkpoint.checkpoint_sequential(self.res_blocks, segments=len(self.res_blocks), input=x) # Use checkpoints for residual blocks\n","        for layer in self.up_blocks:\n","            x = layer(x)\n","        #set_trace()\n","        return torch.tanh(self.last(x))[: , : ,:max_size_x, :(max_size_y)]\n","\n","\n","def train_fn(\n","    disc_Trap, disc_Rock, gen_Rock, gen_Trap, loader, opt_disc, opt_gen, l1, mse, d_scaler, g_scaler, epoch, \n","    D_Trap_real_loss_sum, D_Trap_fake_loss_sum, D_Trap_loss_sum,D_Rock_real_loss_sum, D_Rock_fake_loss_sum, D_Rock_loss_sum, D_loss_sum, \n","    loss_G_Trap_sum, loss_G_Rock_sum,cycle_rock_loss_sum,  cycle_trap_loss_sum, G_loss_sum\n","):\n","    Trap_reals = 0\n","    Trap_fakes = 0\n","    #set_trace()\n","    loop = tqdm(loader, leave=True)\n","    #set_trace()\n","    for idx, (rock, trap) in enumerate(loop):\n","        rock = rock.to(DEVICE, dtype=torch.float32)\n","        trap = trap.to(DEVICE, dtype=torch.float32)\n","        rock = rock.unsqueeze(1)\n","        trap = trap.unsqueeze(1)\n","        # Train Discriminators H and Z\n","        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n","            #set_trace()\n","            fake_trap = gen_Trap(rock)\n","            D_Trap_real = disc_Trap(trap)\n","            D_Trap_fake = disc_Trap(fake_trap.detach())\n","            Trap_reals += D_Trap_real.mean().item()\n","            Trap_fakes += D_Trap_fake.mean().item()\n","\n","            D_Trap_real_loss = mse(D_Trap_real, torch.ones_like(D_Trap_real))\n","            D_Trap_real_loss_sum += D_Trap_real_loss.detach().cpu().numpy().item()\n","\n","            D_Trap_fake_loss = mse(D_Trap_fake, torch.zeros_like(D_Trap_fake))\n","            D_Trap_fake_loss_sum += D_Trap_fake_loss.detach().cpu().numpy().item()\n","\n","            D_Trap_loss = D_Trap_real_loss + D_Trap_fake_loss\n","            D_Trap_loss_sum += D_Trap_loss.detach().cpu().numpy().item()\n","\n","\n","            fake_rock = gen_Rock(trap)\n","            D_Rock_real = disc_Rock(rock)\n","            D_Rock_fake = disc_Rock(fake_rock.detach())\n","            D_Rock_real_loss = mse(D_Rock_real, torch.ones_like(D_Rock_real))\n","            D_Rock_real_loss_sum += D_Rock_real_loss.detach().cpu().numpy().item()\n","\n","            D_Rock_fake_loss = mse(D_Rock_fake, torch.zeros_like(D_Rock_fake))\n","            D_Rock_fake_loss_sum += D_Rock_fake_loss.detach().cpu().numpy().item()\n","\n","            D_Rock_loss = D_Rock_real_loss + D_Rock_fake_loss\n","            D_Rock_loss_sum += D_Rock_loss.detach().cpu().numpy().item()\n","\n","\n","\n","            # put it togethor\n","            D_loss = (D_Trap_loss + D_Rock_loss) / 2\n","            D_loss_sum += D_loss.detach().cpu().numpy().item()\n","\n","\n","        opt_disc.zero_grad(set_to_none=True)\n","        d_scaler.scale(D_loss).backward()\n","        d_scaler.step(opt_disc)\n","        d_scaler.update()\n","\n","        # Train Generators H and Z\n","        with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n","            # adversarial loss for both generators\n","            D_Trap_fake = disc_Trap(fake_trap)\n","            D_Rock_fake = disc_Rock(fake_rock)\n","            loss_G_Trap = mse(D_Trap_fake, torch.ones_like(D_Trap_fake))\n","            loss_G_Trap_sum += loss_G_Trap.detach().cpu().numpy().item()\n","\n","\n","            loss_G_Rock = mse(D_Rock_fake, torch.ones_like(D_Rock_fake))\n","            loss_G_Rock_sum += loss_G_Rock.detach().cpu().numpy().item()\n","\n","\n","            # set_trace()\n","            # cycle loss\n","            cycle_rock = gen_Rock(fake_trap)\n","            cycle_trap = gen_Trap(fake_rock)\n","            cycle_rock_loss = l1(rock, cycle_rock)\n","            cycle_rock_loss_sum += cycle_rock_loss.detach().cpu().numpy().item()\n","\n","            cycle_trap_loss = l1(trap, cycle_trap)\n","            cycle_trap_loss_sum += cycle_trap_loss.detach().cpu().numpy().item()\n","\n","\n","\n","            # add all togethor\n","            G_loss = (\n","                loss_G_Rock\n","                + loss_G_Trap\n","                + cycle_rock_loss * LAMBDA_CYCLE\n","                + cycle_trap_loss * LAMBDA_CYCLE\n","            )\n","            G_loss_sum += G_loss.detach().cpu().numpy().item()\n","\n","\n","        opt_gen.zero_grad(set_to_none=True)\n","        g_scaler.scale(G_loss).backward()\n","        g_scaler.step(opt_gen)\n","        g_scaler.update()\n","\n","        if idx % 10 == 0:\n","            save_image(fake_trap * 0.5 + 0.5, f\"Fake images/trap_{idx}.png\")\n","            save_image(fake_rock * 0.5 + 0.5, f\"Fake images/rock_{idx}.png\")\n","            #set_trace()\n","            hop_length = 512\n","            n_fft = 2048\n","            sr = 22500\n","\n","            #trap audio\n","            spectrogram = cv2.imread(f\"Fake images/trap_{idx}.png\", cv2.IMREAD_GRAYSCALE).astype('float32')\n","            # Normalize the spectrogram to the range [0, 1]\n","            spectrogram /= 255.0\n","            # Reconstruct the audio waveform from the spectrogram\n","            audio = librosa.griffinlim(spectrogram, hop_length=hop_length, win_length=n_fft)\n","            file_name_full = f\"Fake Audio/trap_{idx}_EPOCH{epoch}.wav\"\n","            soundfile.write(file_name_full, audio, samplerate=sr)\n","\n","            #rock audio\n","            spectrogram = cv2.imread(f\"Fake images/rock_{idx}.png\", cv2.IMREAD_GRAYSCALE).astype('float32')\n","            # Normalize the spectrogram to the range [0, 1]\n","            spectrogram /= 255.0\n","            # Reconstruct the audio waveform from the spectrogram\n","            audio = librosa.griffinlim(spectrogram, hop_length=hop_length, win_length=n_fft)\n","            file_name_full = f\"Fake Audio/rock_{idx}_EPOCH{epoch}.wav\"\n","            soundfile.write(file_name_full, audio, samplerate=sr)\n","\n","\n","        loop.set_postfix(Trap_real=Trap_reals / (idx + 1), Trap_fake=Trap_fakes / (idx + 1))\n","    return D_Trap_real_loss_sum,D_Trap_fake_loss_sum,D_Trap_loss_sum,D_Rock_real_loss_sum, D_Rock_fake_loss_sum, D_Rock_loss_sum,D_loss_sum, loss_G_Trap_sum, loss_G_Rock_sum,cycle_rock_loss_sum, cycle_trap_loss_sum, G_loss_sum\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"z-9J-jdRgA96"},"outputs":[{"ename":"AssertionError","evalue":"Torch not compiled with CUDA enabled","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 151\u001b[0m\n\u001b[1;32m    147\u001b[0m         np\u001b[39m.\u001b[39msavetxt(\u001b[39m'\u001b[39m\u001b[39mG_loss.csv\u001b[39m\u001b[39m'\u001b[39m, G_loss_array, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 151\u001b[0m     main()\n","Cell \u001b[0;32mIn[13], line 3\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[0;32m----> 3\u001b[0m     disc_Trap \u001b[39m=\u001b[39m Discriminator(in_channels\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mto(DEVICE)\n\u001b[1;32m      4\u001b[0m     disc_Rock \u001b[39m=\u001b[39m Discriminator(in_channels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m      6\u001b[0m     gen_Rock \u001b[39m=\u001b[39m Generator(img_channels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, num_residuals\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m)\u001b[39m.\u001b[39mto(DEVICE)\n","File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n","File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n","File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n","File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:239\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    236\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n","\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"]}],"source":["def main():\n","  \n","    disc_Trap = Discriminator(in_channels=1).to(DEVICE)\n","    disc_Rock = Discriminator(in_channels=1).to(DEVICE)\n","\n","    gen_Rock = Generator(img_channels=1, num_residuals=9).to(DEVICE)\n","    gen_Trap = Generator(img_channels=1, num_residuals=9).to(DEVICE)\n","    opt_disc = optim.Adam(\n","        list(disc_Trap.parameters()) + list(disc_Rock.parameters()),\n","        lr=LEARNING_RATE,\n","        betas=(0.5, 0.999),\n","    )\n","\n","    opt_gen = optim.Adam(\n","        list(gen_Rock.parameters()) + list(gen_Trap.parameters()),\n","        lr=LEARNING_RATE,\n","        betas=(0.5, 0.999),\n","    )\n","\n","    L1 = nn.L1Loss()\n","    mse = nn.MSELoss()\n","\n","    if LOAD_MODEL:\n","        load_checkpoint(\n","            CHECKPOINT_GEN_Trap,\n","            gen_Trap,\n","            opt_gen,\n","            LEARNING_RATE,\n","        )\n","        load_checkpoint(\n","            CHECKPOINT_GEN_Rock,\n","            gen_Rock,\n","            opt_gen,\n","            LEARNING_RATE,\n","        )\n","        load_checkpoint(\n","            CHECKPOINT_CRITIC_Trap,\n","            disc_Trap,\n","            opt_disc,\n","            LEARNING_RATE,\n","        )\n","        load_checkpoint(\n","            CHECKPOINT_CRITIC_Rock,\n","            disc_Rock,\n","            opt_disc,\n","            LEARNING_RATE,\n","        )\n","\n","    dataset = TrapRockDataset(\n","        root_trap=TRAIN_DIR + \"/trap\",\n","        root_rock=TRAIN_DIR + \"/rock\",\n","        # transform=transforms,\n","    )\n","    val_dataset = TrapRockDataset(\n","        root_trap=VAL_DIR + \"/trap\",\n","        root_rock=VAL_DIR + \"/rock\",\n","        # transform=transforms,\n","    )\n","    val_loader = DataLoader(\n","        val_dataset,\n","        batch_size=1,\n","        shuffle=False,\n","        pin_memory=True,\n","    )\n","    loader = DataLoader(\n","        dataset,\n","        batch_size=BATCH_SIZE,\n","        shuffle=True,\n","        num_workers=NUM_WORKERS,\n","        pin_memory=True,\n","    )\n","    g_scaler = torch.cuda.amp.GradScaler()\n","    d_scaler = torch.cuda.amp.GradScaler()\n","\n","    for epoch in range(NUM_EPOCHS):\n","\n","        D_Trap_real_loss_sum = 0\n","        D_Trap_fake_loss_sum = 0\n","        D_Trap_loss_sum = 0\n","        D_Rock_real_loss_sum = 0\n","        D_Rock_fake_loss_sum = 0\n","        D_Rock_loss_sum = 0\n","        D_loss_sum = 0\n","        loss_G_Trap_sum = 0\n","        loss_G_Rock_sum = 0\n","        cycle_rock_loss_sum = 0\n","        cycle_trap_loss_sum = 0\n","        G_loss_sum = 0\n","\n","        D_Trap_real_loss_sum,D_Trap_fake_loss_sum,D_Trap_loss_sum,D_Rock_real_loss_sum, D_Rock_fake_loss_sum, D_Rock_loss_sum,D_loss_sum, loss_G_Trap_sum, loss_G_Rock_sum,cycle_rock_loss_sum, cycle_trap_loss_sum, G_loss_sum=  train_fn(\n","            disc_Trap,\n","            disc_Rock,\n","            gen_Rock,\n","            gen_Trap,\n","            loader,\n","            opt_disc,\n","            opt_gen,\n","            L1,\n","            mse,\n","            d_scaler,\n","            g_scaler,\n","            epoch,\n","            D_Trap_real_loss_sum,\n","            D_Trap_fake_loss_sum,\n","            D_Trap_loss_sum,\n","            D_Rock_real_loss_sum, \n","            D_Rock_fake_loss_sum, \n","            D_Rock_loss_sum,\n","            D_loss_sum, \n","            loss_G_Trap_sum, \n","            loss_G_Rock_sum,\n","            cycle_rock_loss_sum, \n","            cycle_trap_loss_sum, \n","            G_loss_sum\n","        )\n","\n","        if SAVE_MODEL:\n","            save_checkpoint(gen_Trap, opt_gen, filename=CHECKPOINT_GEN_Trap)\n","            save_checkpoint(gen_Rock, opt_gen, filename=CHECKPOINT_GEN_Rock)\n","            save_checkpoint(disc_Trap, opt_disc, filename=CHECKPOINT_CRITIC_Trap)\n","            save_checkpoint(disc_Rock, opt_disc, filename=CHECKPOINT_CRITIC_Rock)\n","\n","        D_Trap_real_loss_array.append(D_Trap_real_loss_sum)\n","        D_Trap_fake_loss_array.append(D_Trap_fake_loss_sum)\n","        D_Trap_loss_array.append(D_Trap_loss_sum)\n","        D_Rock_real_loss_array.append(D_Rock_real_loss_sum)\n","        D_Rock_fake_loss_array.append(D_Rock_fake_loss_sum)\n","        D_Rock_loss_array.append(D_Rock_loss_sum)\n","        D_loss_array.append(D_loss_sum)\n","        loss_G_Trap_array.append(loss_G_Trap_sum)\n","        loss_G_Rock_array.append(loss_G_Rock_sum)\n","        cycle_rock_loss_array.append(cycle_rock_loss_sum)\n","        cycle_trap_loss_array.append(cycle_trap_loss_sum)\n","        G_loss_array.append(G_loss_sum)\n","\n","        np.savetxt('D_Trap_real_loss.csv', D_Trap_real_loss_array, delimiter=',')\n","        np.savetxt('D_Trap_fake_loss.csv', D_Trap_fake_loss_array, delimiter=',')\n","        np.savetxt('D_Trap_loss.csv', D_Trap_loss_array, delimiter=',')\n","        np.savetxt('D_Rock_real_loss.csv', D_Rock_real_loss_array, delimiter=',')\n","        np.savetxt('D_Rock_fake_loss.csv', D_Rock_fake_loss_array, delimiter=',')\n","        np.savetxt('D_Rock_loss.csv', D_Rock_loss_array, delimiter=',')\n","        np.savetxt('D_loss.csv', D_loss_array, delimiter=',')\n","        np.savetxt('loss_G_Trap.csv', loss_G_Trap_array, delimiter=',')\n","        np.savetxt('loss_G_Rock.csv', loss_G_Rock_array, delimiter=',')\n","        np.savetxt('cycle_rock_loss.csv', cycle_rock_loss_array, delimiter=',')\n","        np.savetxt('cycle_trap_loss.csv', cycle_trap_loss_array, delimiter=',')\n","        np.savetxt('G_loss.csv', G_loss_array, delimiter=',')\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
